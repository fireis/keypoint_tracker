{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "In this notebook, we take a look at some good image datasets and the respective peculiarities\n",
    "\n",
    "## NOTE: THIS IS A WORK IN PROGRESS, INTENDED TO BE ONLY A QUICK GUIDE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Kaggle Competition - Facial Keypoints Detection](https://www.kaggle.com/c/facial-keypoints-detection/data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is composed by 8832 images, being 7049 on the training and 1783 on the test set. This dataset also contains coordinates for 15 key facial points for each image. \n",
    "Each image has 96x96 pixels.\n",
    "#### The good: simple and easy-to-use dataset, with many banchmarks available at ir original Kaggle page\n",
    "\n",
    "#### The bad: images are annotated with only 15 key facial points\n",
    "\n",
    "#### Conclusion: I would use this dataset to validate ML models but it's not the best to expression mapping/cloning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [MUCT Face Database](http://www.milbo.org/muct/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Researchers of the University of Cape Town created the MUCT dataset, which contains 3755 faces, each with 76 facial landmarks manually positioned. This dataset includes some subjects photographed in different angles and with different light exposure. The images have a resolution of 480x640 pixels.\n",
    "\n",
    "### The good: diverse dataset with almost \"in the wild\" approach and with a decent amount of manually positioned landmarks (76);\n",
    "\n",
    "### The bad: only 276 subjects, which may be small for some projects, like facial identification;\n",
    "\n",
    "### Conclusion: great dataset for facial landmark models\n",
    "\n",
    "***\n",
    "@article{Milborrow10,\n",
    "  author={S. Milborrow and J. Morkel and F. Nicolls},\n",
    "  title={{The MUCT Landmarked Face Database}},\n",
    "  journal={Pattern Recognition Association of South Africa},\n",
    "  year=2010,\n",
    "  note={\\url{http://www.milbo.org/muct}}\n",
    "}\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [300 Faces In-the-Wild Challenge (300-W), ICCV 2013](https://ibug.doc.ic.ac.uk/resources/300-W/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [LFPW](https://neerajkumar.org/databases/lfpw/)\n",
    "\n",
    "This dataset contains 1432 images obtained from the web, each manually annotated (using Amazon Mechancal Turk) with 29 labelled landmarks\n",
    "\n",
    "***\n",
    "\"Localizing Parts of Faces Using a Consensus of Exemplars,\"\n",
    "\n",
    "Peter N. Belhumeur, David W. Jacobs, David J. Kriegman, Neeraj Kumar,\n",
    "\n",
    "Proceedings of the 24th IEEE Conference on Computer Vision and Pattern Recognition (CVPR),\n",
    "\n",
    "June 2011.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Helen](http://www.ifp.illinois.edu/~vuongle2/helen/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
